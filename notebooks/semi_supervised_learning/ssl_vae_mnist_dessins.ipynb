{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why semi-supervised learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stats.stackexchange.com/questions/321841/what-are-variational-autoencoders-and-to-what-learning-tasks-are-they-used\n",
    "\n",
    "Ideal parameters:\n",
    "$$ \\min_{\\boldsymbol{\\lambda}}\\mathcal{D}[p(\\mathbf{z}\\vert \\mathbf{x})\\vert\\vert q(\\mathbf{z}\\vert \\mathbf{x},\\boldsymbol{\\lambda})] $$\n",
    "\n",
    "It should also minimize the reconstruction loss (and optional regularization terms, mainly L1 or L2)\n",
    "\n",
    "VAE loss function:\n",
    "$$ELBO(\\boldsymbol{\\lambda})= E_{q(\\boldsymbol{z}\\vert \\mathbf{x},\\boldsymbol{\\lambda})}[\\log p(\\mathbf{x}\\vert\\boldsymbol{z})]-\\mathcal{D}[(q(\\boldsymbol{z}\\vert \\mathbf{x},\\boldsymbol{\\lambda})\\vert\\vert p(\\boldsymbol{z})]$$\n",
    "\n",
    "$$ q(\\mathbf{z}\\vert \\mathbf{x},\\boldsymbol{\\lambda}) = \\mathcal{N}(\\mathbf{z}\\vert\\boldsymbol{\\mu}(\\mathbf{x}), \\boldsymbol{\\sigma}^2(\\mathbf{x})I) $$\n",
    "\n",
    "conditional distribution:\n",
    "$$ p_{\\boldsymbol{\\phi}}(\\mathbf{x}\\vert\\mathbf{z}) = \\mathcal{N}(\\mathbf{x}|\\boldsymbol{\\mu}(\\mathbf{z}; \\boldsymbol{\\phi}), \\boldsymbol{\\sigma}(\\mathbf{z}; \\boldsymbol{\\phi})^2I)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ ELBO(\\boldsymbol{\\theta},\\boldsymbol{\\phi})= \\sum_i E_{q_{\\boldsymbol{\\theta}}(\\boldsymbol{z}\\vert \\mathbf{x}_i,\\boldsymbol{\\lambda})}[\\log p_{\\boldsymbol{\\phi}}(\\mathbf{x}_i\\vert\\boldsymbol{z})]-\\mathcal{D}[(q_{\\boldsymbol{\\theta}}(\\boldsymbol{z}\\vert \\mathbf{x}_i,\\boldsymbol{\\lambda})\\vert\\vert p(\\boldsymbol{z})] $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import os\n",
    "os.chdir(\"../..\")\n",
    "from data_preparation.GeoParser import GeoParser\n",
    "from dimension_reduction.ordination import ordination2d\n",
    "from sklearn.decomposition import PCA\n",
    "from IPython.display import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from models.semi_supervised.deep_generative_models.models.auxiliary_dgm import AuxiliaryDeepGenerativeModel\n",
    "from utils.utils import dict_of_int_highest_elements, plot_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# files_destinations\n",
    "home_path = \"/home/simon/\"\n",
    "destination_folder = \"annleukemia\"\n",
    "data_folder = \"data\"\n",
    "results_folder = \"results\"\n",
    "meta_destination_folder = \"pandas_meta_df\"\n",
    "\n",
    "plots_folder_path = \"/\".join([home_path, destination_folder, results_folder, \"plots/\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#dataset_name = \"gse33000_and_GSE24335_GSE44768_GSE44771_GSE44770\"\n",
    "dataset_name = \"dessins\"\n",
    "activation = \"relu\"\n",
    "#nrep = 3\n",
    "betas=(0.9, 0.999)\n",
    "vae_flavour = \"o-sylvester\"\n",
    "early_stopping = 200\n",
    "labels_per_class = 10000\n",
    "n_epochs = 1000\n",
    "warmup = 100\n",
    "gt_input = 10000\n",
    "\n",
    "# if ladder is yes builds a ladder vae. Do not combine with auxiliary (yet; might be possible and relatively \n",
    "# not too hard to implement, but might be overkill. Might be interesting too)\n",
    "translate = \"n\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Types of deep generative model\n",
    "\n",
    "# Convolution neural network (convolutional VAE and convolutional classifier)\n",
    "use_conv_ae = False #Not applicable if not sequence (images, videos, sentences, DNA...)\n",
    "use_convnet = True\n",
    "# Ladder VAE (L-VAE)\n",
    "ladder = False\n",
    "\n",
    "# Auxiliary Variational Auto-Encoder (A-VAE)\n",
    "auxiliary = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load pre-computed vae (unsupervised learning)\n",
    "load_vae = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition of the hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lr = 3e-4\n",
    "l1 = 0.\n",
    "l2 = 0.\n",
    "batch_size = 32\n",
    "mc = 1 # seems to be a problem when mc > 1 for display only, results seem good\n",
    "iw = 1 # seems to be a problem when iw > 1 for display only, results seem good\n",
    "\n",
    "# Neurons layers\n",
    "a_dim = 100\n",
    "h_dims_classifier = [512]\n",
    "h_dims = [512, 256, 128]\n",
    "z_dims = [100]\n",
    "\n",
    "# number of flows\n",
    "number_of_flows = 10\n",
    "num_elements = 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Files destinations\n",
    "load_from_disk = True\n",
    "load_merge = False\n",
    "home_path = \"/home/simon/\"\n",
    "destination_folder = \"annleukemia\"\n",
    "data_folder = \"data\"\n",
    "results_folder = \"results\"\n",
    "meta_destination_folder = \"pandas_meta_df\"\n",
    "plots_folder_path = \"/\".join([home_path, destination_folder, \n",
    "                              results_folder, \"plots/\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_dim (making sure it stays ok for ssl_vae) 0\n",
      "self.a_dim 100\n"
     ]
    }
   ],
   "source": [
    "if auxiliary:\n",
    "    dgm = AuxiliaryDeepGenerativeModel(vae_flavour, z_dims, h_dims, n_flows=number_of_flows,a_dim=a_dim,\n",
    "                                       num_elements=num_elements, is_hebb_layers=True,\n",
    "                                       gt_input=gt_input)\n",
    "\n",
    "    dgm.set_configs(home_path=home_path, results_folder=results_folder, data_folder=data_folder,\n",
    "                    destination_folder=destination_folder, dataset_name=dataset_name, lr=lr,\n",
    "                    meta_destination_folder=\"meta_pandas_dataframes\", csv_filename=\"csv_loggers\", \n",
    "                    is_unlabelled=True)\n",
    "\n",
    "elif ladder:\n",
    "    dgm = LadderDeepGenerativeModel(vae_flavour, z_dims, h_dims, n_flows=number_of_flows, auxiliary=False,\n",
    "                                    is_hebb_layers=True, gt_input=gt_input)\n",
    "\n",
    "    dgm.set_configs(home_path=home_path, results_folder=results_folder, data_folder=data_folder,\n",
    "                    destination_folder=destination_folder, dataset_name=dataset_name, lr=lr,\n",
    "                    meta_destination_folder=\"meta_pandas_dataframes\", csv_filename=\"csv_loggers\", \n",
    "                    is_unlabelled=True)\n",
    "else:\n",
    "    dgm = DeepGenerativeModel(vae_flavour, z_dims, h_dims, n_flows=number_of_flows, a_dim=0, auxiliary=False,\n",
    "                              num_elements=num_elements, is_hebb_layers=False, gt_input=gt_input)\n",
    "\n",
    "    dgm.set_configs(home_path=home_path, results_folder=results_folder, data_folder=data_folder,\n",
    "                    destination_folder=destination_folder, dataset_name=dataset_name, lr=lr,\n",
    "                    meta_destination_folder=\"meta_pandas_dataframes\", csv_filename=\"csv_loggers\", \n",
    "                    is_unlabelled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUMBER OF LABELS 9001\n",
      "Limited number of labels: 10000\n",
      "self.train_loader 282\n",
      "self.train_loader 32\n",
      "self.train_loader <torch.utils.data.sampler.SubsetRandomSampler object at 0x7f8bb7df58d0>\n"
     ]
    }
   ],
   "source": [
    "dgm.load_local_dataset(root_train=\"/home/simon/annleukemia/data/kaggle_dessins/train\", \n",
    "                       root_valid=\"/home/simon/annleukemia/data/kaggle_dessins/valid\",\n",
    "                       root_test=\"/home/simon/annleukemia/data/kaggle_dessins/test\", n_classes=31,\n",
    "                       batch_size=batch_size, labels_per_class=labels_per_class, \n",
    "                       extra_class=True, unlabelled_train_ds=True, normalize=False, mu=0.5, var=0.5)\n",
    "\n",
    "is_example = False\n",
    "# GET ordination from this!\n",
    "train = np.vstack([x[0].data.numpy() for x in dgm.x_train])\n",
    "#unlabelled_train = np.vstack([x[0].data.numpy() for x in dgm.unlabelled_x_train])\n",
    "\n",
    "targets = np.vstack([x[1].data.numpy() for x in dgm.x_train])\n",
    "labels = [x.tolist().index(1) for x in targets]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dgm.define_configurations(early_stopping=early_stopping, warmup=warmup, flavour=vae_flavour)\n",
    "dgm.set_data(labels_per_class=labels_per_class, is_example=True, extra_class=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.input_size 10000\n",
      "Log file created:  logs/AuxiliaryDeepGenerativeModel_parameters.log\n",
      "Log file created:  logs/AuxiliaryDeepGenerativeModel_involvment.log\n",
      "Log file created:  logs/AuxiliaryDeepGenerativeModel.log\n",
      "Labeled shape 282\n",
      "Unlabeled shape 282\n",
      "epoch 0\n",
      "Progress: 0.35%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simon/anaconda3/envs/annleukemia/lib/python3.6/site-packages/torch/tensor.py:255: UserWarning: non-inplace resize is deprecated\n",
      "  warnings.warn(\"non-inplace resize is deprecated\")\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "input has less dimensions than expected",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-0a4e65d20f6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m dgm.run(n_epochs, auxiliary, mc, iw, lambda1=l1, lambda2=l2, verbose=2, \n\u001b[1;32m     35\u001b[0m         \u001b[0mshow_progress\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_pca_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_lda_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_pca_generated\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         is_input_pruning=True, start_pruning=3, show_lda_generated=10, warmup_n=0)\n\u001b[0m",
      "\u001b[0;32m~/annleukemia/models/semi_supervised/deep_generative_models/models/dgm.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, n_epochs, auxiliary, mc, iw, lambda1, lambda2, verbose, show_progress, show_pca_train, show_lda_train, show_pca_valid, show_pca_generated, clip_grad, warmup_n, is_input_pruning, start_pruning, schedule, show_lda_generated, is_balanced_relu, limit_examples, keep_history, decay)\u001b[0m\n\u001b[1;32m    414\u001b[0m                 \u001b[0mL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melbo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid_bool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m                 \u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melbo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_bool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid_bool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m                 \u001b[0;31m# Add auxiliary classification loss q(y|x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/annleukemia/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/annleukemia/models/semi_supervised/deep_generative_models/inference/variational.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, y, valid_bool)\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreconstruction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_bool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_bool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0mL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/annleukemia/models/semi_supervised/deep_generative_models/models/auxiliary_dgm.py\u001b[0m in \u001b[0;36mclassify\u001b[0;34m(self, x, valid_bool, input_pruning, start_pruning)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minput_pruning\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mstart_pruning\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mstart_pruning\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mvalid_bool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_bool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_bool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_bool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/annleukemia/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/annleukemia/models/discriminative/artificial_neural_networks/ConvNet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, a, valid_bool, start_pruning)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv_bn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpooling_layer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_bn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpooling_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m             \u001b[0mconv_bn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/annleukemia/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/annleukemia/models/generative/autoencoders/vae/GatedConv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/annleukemia/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/annleukemia/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 301\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: input has less dimensions than expected"
     ]
    }
   ],
   "source": [
    "planes_classifier = [1, 8, 12, 16, 20]\n",
    "classifier_kernels = [3, 3, 3, 3, 3]\n",
    "classifier_padding = [1, 1, 1, 1, 1]\n",
    "classifier_strides = [1, 1, 1, 1, 1]\n",
    "classifier_maxpool_kernel_size = [2, 2, 2, 2, 2]\n",
    "classifier_maxpool_stride = [2, 2, 2, 2, 2]\n",
    "classifier_pooling_layers = [True, True, True, True, True, True, False, False]\n",
    "\n",
    "if auxiliary:\n",
    "    if use_conv_ae:\n",
    "        dgm.set_conv_adgm_layers()\n",
    "    else:\n",
    "        dgm.set_adgm_layers(h_dims=h_dims_classifier, input_shape=[1, 100, 100], use_conv_classifier=use_convnet, planes_classifier=planes_classifier,\n",
    "                            classifier_kernels=classifier_kernels, classifier_pooling_layers=classifier_pooling_layers)\n",
    "elif ladder:\n",
    "    dgm.set_ldgm_layers(hebb_layers=True, n_channels=1)\n",
    "else:\n",
    "    if use_conv:\n",
    "        dgm.set_conv_dgm_layers(hebb_layers=False)\n",
    "    else:\n",
    "        print(\"MAIN DGM NS\")\n",
    "        dgm.set_dgm_layers(hebb_layers=False)\n",
    "\n",
    "# import the M1 in the M1+M2 model (Kingma et al, 2014). Not sure if it still works... \n",
    "if load_vae:\n",
    "    print(\"Importing the model: \", dgm.model_file_name)\n",
    "    if use_conv:\n",
    "        dgm.import_cvae()\n",
    "    else:\n",
    "        dgm.load_model()\n",
    "    #dgm.set_dgm_layers_pretrained()\n",
    "dgm.cuda()\n",
    "# dgm.vae.generate_random(False, batch_size, z1_size, [1, 28, 28])\n",
    "dgm.run(n_epochs, auxiliary, mc, iw, lambda1=l1, lambda2=l2, verbose=2, \n",
    "        show_progress=10, show_pca_train=10, show_lda_train=10, show_pca_generated=10, clip_grad=1e-3, \n",
    "        is_input_pruning=True, start_pruning=3, show_lda_generated=10, warmup_n=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References\n",
    "Auto-Encoding Variational Bayes https://arxiv.org/abs/1312.6114\n",
    "Semi-Supervised Learning with Deep Generative Models https://arxiv.org/abs/1406.5298\n",
    "Ladder Variational Autoencoders https://arxiv.org/abs/1602.02282\n",
    "Auxiliary Deep Generative Models    https://arxiv.org/abs/1602.05473\n",
    "Sylvester Normalizing Flows for Variational Inference  https://arxiv.org/abs/1803.05649\n",
    "Improving Variational Auto-Encoders using Householder Flow https://arxiv.org/abs/1611.09630\n",
    "Variational Inference with Normalizing Flows https://arxiv.org/abs/1505.05770\n",
    "Convex combination linear IAF and the Householder Flow, J.M. Tomczak & M. Welling https://jmtomczak.github.io/deebmed.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Github Ressources:\n",
    "    https://github.com/wohlert/semi-supervised-pytorch\n",
    "    https://github.com/jmtomczak/vae_vpflows\n",
    "    https://github.com/jmtomczak/vae_householder_flow"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "TO DO:\n",
    "    Calculate negative log-likelihood (to be maximized)\n",
    "    Get ordinations for all_samples AND generated samples in the SAME plot; \n",
    "        (make them the same color, but only the genwerated with a black contour, \n",
    "        or the opposite, or different contours)\n",
    "    Add Inverse Autoregressive Flow for variational inference (IAF; very common and apparently good; \n",
    "        the base for other flavours, such as sylvester flows (to be verified)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
