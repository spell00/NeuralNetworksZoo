{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why semi-supervised learning?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stats.stackexchange.com/questions/321841/what-are-variational-autoencoders-and-to-what-learning-tasks-are-they-used\n",
    "\n",
    "Ideal parameters:\n",
    "$$ \\min_{\\boldsymbol{\\lambda}}\\mathcal{D}[p(\\mathbf{z}\\vert \\mathbf{x})\\vert\\vert q(\\mathbf{z}\\vert \\mathbf{x},\\boldsymbol{\\lambda})] $$\n",
    "\n",
    "It should also minimize the reconstruction loss (and optional regularization terms, mainly L1 or L2)\n",
    "\n",
    "VAE loss function:\n",
    "$$ELBO(\\boldsymbol{\\lambda})= E_{q(\\boldsymbol{z}\\vert \\mathbf{x},\\boldsymbol{\\lambda})}[\\log p(\\mathbf{x}\\vert\\boldsymbol{z})]-\\mathcal{D}[(q(\\boldsymbol{z}\\vert \\mathbf{x},\\boldsymbol{\\lambda})\\vert\\vert p(\\boldsymbol{z})]$$\n",
    "\n",
    "$$ q(\\mathbf{z}\\vert \\mathbf{x},\\boldsymbol{\\lambda}) = \\mathcal{N}(\\mathbf{z}\\vert\\boldsymbol{\\mu}(\\mathbf{x}), \\boldsymbol{\\sigma}^2(\\mathbf{x})I) $$\n",
    "\n",
    "conditional distribution:\n",
    "$$ p_{\\boldsymbol{\\phi}}(\\mathbf{x}\\vert\\mathbf{z}) = \\mathcal{N}(\\mathbf{x}|\\boldsymbol{\\mu}(\\mathbf{z}; \\boldsymbol{\\phi}), \\boldsymbol{\\sigma}(\\mathbf{z}; \\boldsymbol{\\phi})^2I)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ ELBO(\\boldsymbol{\\theta},\\boldsymbol{\\phi})= \\sum_i E_{q_{\\boldsymbol{\\theta}}(\\boldsymbol{z}\\vert \\mathbf{x}_i,\\boldsymbol{\\lambda})}[\\log p_{\\boldsymbol{\\phi}}(\\mathbf{x}_i\\vert\\boldsymbol{z})]-\\mathcal{D}[(q_{\\boldsymbol{\\theta}}(\\boldsymbol{z}\\vert \\mathbf{x}_i,\\boldsymbol{\\lambda})\\vert\\vert p(\\boldsymbol{z})] $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Import packages\n",
    "from data_preparation.GeoParser import GeoParser\n",
    "from dimension_reduction.ordination import ordination2d\n",
    "from sklearn.decomposition import PCA\n",
    "from IPython.display import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simon/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O-sylvester\n"
     ]
    }
   ],
   "source": [
    "from models.generative.autoencoders.vae.vae import VariationalAutoencoder\n",
    "from models.generative.autoencoders.vae.ladder_vae import LadderVariationalAutoencoder\n",
    "from models.generative.autoencoders.vae.sylvester_vae import SylvesterVAE\n",
    "from utils.utils import dict_of_int_highest_elements, plot_evaluation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# files_destinations\n",
    "home_path = \"/home/simon/\"\n",
    "destination_folder = \"annleukemia\"\n",
    "data_folder = \"data\"\n",
    "results_folder = \"results\"\n",
    "meta_destination_folder = \"pandas_meta_df\"\n",
    "\n",
    "plots_folder_path = \"/\".join([home_path, destination_folder, results_folder, \"plots/\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#dataset_name = \"gse33000_and_GSE24335_GSE44768_GSE44771_GSE44770\"\n",
    "dataset_name = \"gse33000+4\"\n",
    "geo_ids = [\"GSE33000\"]\n",
    "# Contrary to ssl, I don't also put the labelled ID in the unlabelled, as it is just redundent here\n",
    "unlabelled_geo_ids = [\"GSE33000\"] \n",
    "activation = \"relu\"\n",
    "#nrep = 3\n",
    "betas=(0.9, 0.999)\n",
    "vae_flavour = \"o-sylvester\"\n",
    "early_stopping = 200\n",
    "labels_per_class = 0\n",
    "n_epochs = 100\n",
    "warmup = 0\n",
    "gt_input = 0\n",
    "\n",
    "# if ladder is yes builds a ladder vae. Do not combine with auxiliary (yet; might be possible and relatively \n",
    "# not too hard to implement, but might be overkill. Might be interesting too)\n",
    "translate = \"n\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Types of deep generative model\n",
    "\n",
    "# Convolution neural network (convolutional VAE and convolutional classifier)\n",
    "use_conv = False #Not applicable if not sequence (images, videos, sentences, DNA...)\n",
    "\n",
    "# Ladder VAE (L-VAE)\n",
    "ladder = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load pre-computed vae (unsupervised learning)\n",
    "load_vae = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition of the hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lr = 1e-4\n",
    "l1 = 0.\n",
    "l2 = 0.\n",
    "batch_size = 128\n",
    "mc = 1 # seems to be a problem when mc > 1 for display only, results seem good\n",
    "iw = 1 # seems to be a problem when iw > 1 for display only, results seem good\n",
    "\n",
    "# Neurons layers\n",
    "h_dims = [128, 64]\n",
    "z_dims = [50]\n",
    "\n",
    "# number of flows\n",
    "n_combinations = 20 #could be just 1 with number_of_flows?\n",
    "number_of_flows = 8\n",
    "num_elements = 3\n",
    "\n",
    "is_example = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bad_geo_ids = [\"\"] # Now useless, didn't work well, but stil complains without it. to be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Files destinations\n",
    "load_from_disk = True\n",
    "load_merge = False\n",
    "home_path = \"/home/simon/\"\n",
    "destination_folder = \"annleukemia\"\n",
    "data_folder = \"data\"\n",
    "results_folder = \"results\"\n",
    "meta_destination_folder = \"pandas_meta_df\"\n",
    "plots_folder_path = \"/\".join([home_path, destination_folder, \n",
    "                              results_folder, \"plots/\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running: GSE33000\n",
      "Loading GSE33000, labelled: True ...\n",
      "File found at location: /home/simon//annleukemia/data//GSE33000_labelledTrue_dataframe.pickle.npy\n",
      "self.df[geo_id] (35371, 624)\n",
      "\n",
      "Running unlabelled: GSE33000\n",
      "Loading GSE33000, labelled: False ...\n",
      "File found at location: /home/simon//annleukemia/data//GSE33000_labelledFalse_dataframe.pickle.npy\n",
      "self.unlabelled_df[geo_id] (35371, 624)\n",
      "Preparing for merging the selected datasets... labelled: True\n",
      "The file you were looking for is there\n",
      "File found!\n",
      "merging file: 1 / 1\n",
      "(35371, 624)\n",
      "Saving files...\n",
      "Merged sets loaded.\n",
      "Preparing for merging the selected datasets... labelled: False\n",
      "The file you were looking for is there\n",
      "File found!\n",
      "merging file: 1 / 1\n",
      "(35371, 624)\n",
      "Saving files...\n",
      "Merged sets loaded.\n"
     ]
    }
   ],
   "source": [
    "from utils.utils import adapt_datasets\n",
    "g = GeoParser(home_path=home_path, geo_ids=geo_ids, unlabelled_geo_ids=unlabelled_geo_ids, bad_geo_ids=None)\n",
    "g.get_geo(load_from_disk=load_from_disk, automatic_attribute_list=None)\n",
    "meta_df = g.merge_datasets(load_from_disk=load_merge, labelled=True)\n",
    "unlabelled_meta_df = g.merge_datasets(load_from_disk=load_merge, labelled=False)\n",
    "if translate is \"y\":\n",
    "    for geo_id in geo_ids:\n",
    "        g.translate_indices_df(geo_id, labelled=True)\n",
    "    for geo_id in unlabelled_geo_ids:\n",
    "        g.translate_indices_df(geo_id, labelled=False)\n",
    "\n",
    "#meta_df, unlabelled_meta_df = adapt_datasets(meta_df, unlabelled_meta_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vae_flavour o-sylvester\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'a_dim' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-16ef9aad22eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"vae_flavour\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvae_flavour\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     vae = SylvesterVAE(vae_flavour, z_dims=z_dims, h_dims=h_dims, n_flows=number_of_flows,\n\u001b[0;32m----> 8\u001b[0;31m                        num_elements=num_elements, auxiliary=False, a_dim=a_dim)\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"vae_flavour\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvae_flavour\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'a_dim' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "if ladder:\n",
    "    vae = LadderVariationalAutoencoder(vae_flavour, z_dims=z_dims, h_dims=h_dims, n_flows=number_of_flows,\n",
    "                                       num_elements=num_elements, a_dim=0)\n",
    "    z_dim = z_dims[-1]\n",
    "elif vae_flavour in [\"o-sylvester\", \"h-sylvester\", \"t-sylvester\"]:\n",
    "    print(\"vae_flavour\", vae_flavour)\n",
    "    vae = SylvesterVAE(vae_flavour, z_dims=z_dims, h_dims=h_dims, n_flows=number_of_flows,\n",
    "                       num_elements=num_elements, auxiliary=False, a_dim=0)\n",
    "else:\n",
    "    print(\"vae_flavour\", vae_flavour)\n",
    "    vae = VariationalAutoencoder(vae_flavour, z_dim=z_dims, h_dims=h_dims, n_flows=number_of_flows,\n",
    "                                 auxiliary=False, a_dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.set_configs(home_path=home_path, results_folder=results_folder, data_folder=data_folder,\n",
    "               destination_folder=destination_folder, dataset_name=dataset_name, lr=lr,\n",
    "               meta_destination_folder=\"meta_pandas_dataframes\", csv_filename=\"csv_loggers\", is_unlabelled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Labeled data shape (35371, 624)\", meta_df.shape)\n",
    "print(\"unlabelled meta_df shape\", unlabelled_meta_df.shape)\n",
    "\n",
    "if meta_df is not None:\n",
    "    vae.import_dataframe(meta_df, batch_size, labelled=True)\n",
    "    vae.import_dataframe(unlabelled_meta_df, batch_size, labelled=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"PCA saved at: \", plots_folder_path)\n",
    "ordination2d(meta_df, epoch=\"pre\", dataset_name=dataset_name, ord_type=\"pca\",\n",
    "             images_folder_path=plots_folder_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.define_configurations(vae_flavour, early_stopping=100, warmup=warmup, ladder=ladder, z_dim=z_dims[-1], \n",
    "                          auxiliary=False, ssl=False)\n",
    "vae.set_data(is_example=False, labels_per_class=labels_per_class)\n",
    "if ladder:\n",
    "    print(\"Setting ladder layers\")\n",
    "    vae.set_lvae_layers()\n",
    "else:\n",
    "    vae.set_vae_layers()\n",
    "\n",
    "if load_vae:\n",
    "    vae.load_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.run(epochs=n_epochs, clip_grad=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References\n",
    "Auto-Encoding Variational Bayes https://arxiv.org/abs/1312.6114\n",
    "Semi-Supervised Learning with Deep Generative Models https://arxiv.org/abs/1406.5298\n",
    "Ladder Variational Autoencoders https://arxiv.org/abs/1602.02282\n",
    "Auxiliary Deep Generative Models    https://arxiv.org/abs/1602.05473\n",
    "Sylvester Normalizing Flows for Variational Inference  https://arxiv.org/abs/1803.05649\n",
    "Improving Variational Auto-Encoders using Householder Flow https://arxiv.org/abs/1611.09630\n",
    "Variational Inference with Normalizing Flows https://arxiv.org/abs/1505.05770\n",
    "Convex combination linear IAF and the Householder Flow, J.M. Tomczak & M. Welling https://jmtomczak.github.io/deebmed.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Github Ressources:\n",
    "    https://github.com/wohlert/semi-supervised-pytorch\n",
    "    https://github.com/jmtomczak/vae_vpflows\n",
    "    https://github.com/jmtomczak/vae_householder_flow"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "TO DO:\n",
    "    Calculate negative log-likelihood (to be maximized)\n",
    "    Get ordinations for all_samples AND generated samples in the SAME plot; \n",
    "        (make them the same color, but only the genwerated with a black contour, \n",
    "        or the opposite, or different contours)\n",
    "    Add Inverse Autoregressive Flow for variational inference (IAF; very common and apparently good; \n",
    "        the base for other flavours, such as sylvester flows (to be verified)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
