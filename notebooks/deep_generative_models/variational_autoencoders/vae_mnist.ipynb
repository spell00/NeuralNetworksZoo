{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why semi-supervised learning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../../../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stats.stackexchange.com/questions/321841/what-are-variational-autoencoders-and-to-what-learning-tasks-are-they-used\n",
    "\n",
    "Ideal parameters:\n",
    "$$ \\min_{\\boldsymbol{\\lambda}}\\mathcal{D}[p(\\mathbf{z}\\vert \\mathbf{x})\\vert\\vert q(\\mathbf{z}\\vert \\mathbf{x},\\boldsymbol{\\lambda})] $$\n",
    "\n",
    "It should also minimize the reconstruction loss (and optional regularization terms, mainly L1 or L2)\n",
    "\n",
    "VAE loss function:\n",
    "$$ELBO(\\boldsymbol{\\lambda})= E_{q(\\boldsymbol{z}\\vert \\mathbf{x},\\boldsymbol{\\lambda})}[\\log p(\\mathbf{x}\\vert\\boldsymbol{z})]-\\mathcal{D}[(q(\\boldsymbol{z}\\vert \\mathbf{x},\\boldsymbol{\\lambda})\\vert\\vert p(\\boldsymbol{z})]$$\n",
    "\n",
    "$$ q(\\mathbf{z}\\vert \\mathbf{x},\\boldsymbol{\\lambda}) = \\mathcal{N}(\\mathbf{z}\\vert\\boldsymbol{\\mu}(\\mathbf{x}), \\boldsymbol{\\sigma}^2(\\mathbf{x})I) $$\n",
    "\n",
    "conditional distribution:\n",
    "$$ p_{\\boldsymbol{\\phi}}(\\mathbf{x}\\vert\\mathbf{z}) = \\mathcal{N}(\\mathbf{x}|\\boldsymbol{\\mu}(\\mathbf{z}; \\boldsymbol{\\phi}), \\boldsymbol{\\sigma}(\\mathbf{z}; \\boldsymbol{\\phi})^2I)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ ELBO(\\boldsymbol{\\theta},\\boldsymbol{\\phi})= \\sum_i E_{q_{\\boldsymbol{\\theta}}(\\boldsymbol{z}\\vert \\mathbf{x}_i,\\boldsymbol{\\lambda})}[\\log p_{\\boldsymbol{\\phi}}(\\mathbf{x}_i\\vert\\boldsymbol{z})]-\\mathcal{D}[(q_{\\boldsymbol{\\theta}}(\\boldsymbol{z}\\vert \\mathbf{x}_i,\\boldsymbol{\\lambda})\\vert\\vert p(\\boldsymbol{z})] $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'log_gaussian'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-35b242a7a7be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Import models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerative\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautoencoders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvae\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVariationalAutoencoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerative\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautoencoders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msylvester_vae\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSylvesterVAE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdict_of_int_highest_elements\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/NeuralNetworksZoo-master/lib/python3.6/site-packages/NeuralNetworksZoo_master-0.2-py3.6.egg/models/generative/autoencoders/vae/vae.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerative\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautoencoders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautoencoder\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msemi_supervised\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeep_generative_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstochastic\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGaussianSample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGumbelSoftmax\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/NeuralNetworksZoo-master/lib/python3.6/site-packages/NeuralNetworksZoo_master-0.2-py3.6.egg/models/generative/autoencoders/autoencoder.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcreate_missing_folders\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNeuralNet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNeuralNet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msemi_supervised\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmse_loss_function\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcalculate_losses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/NeuralNetworksZoo-master/lib/python3.6/site-packages/NeuralNetworksZoo_master-0.2-py3.6.egg/models/semi_supervised/utils/loss.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlog_gaussian\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_standard_gaussian\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_bernoulli\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'log_gaussian'"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "#from models.dimension_reduction.ordination import ordination2d\n",
    "#from sklearn.decomposition import PCA\n",
    "from IPython.display import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Import models\n",
    "from models.generative.autoencoders.vae.vae import VariationalAutoencoder\n",
    "from models.generative.autoencoders.vae.sylvester_vae import SylvesterVAE\n",
    "from models.utils.utils import dict_of_int_highest_elements, plot_evaluation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# files_destinations\n",
    "home_path = \"/home/simon/\"\n",
    "destination_folder = \"annleukemia\"\n",
    "data_folder = \"data\"\n",
    "results_folder = \"results\"\n",
    "meta_destination_folder = \"pandas_meta_df\"\n",
    "\n",
    "plots_folder_path = \"/\".join([home_path, destination_folder, results_folder, \"plots/\"])\n",
    "\n",
    "#dataset_name = \"gse33000_and_GSE24335_GSE44768_GSE44771_GSE44770\"\n",
    "dataset_name = \"mnist\"\n",
    "activation = \"relu\"\n",
    "#nrep = 3\n",
    "betas=(0.9, 0.999)\n",
    "vae_flavour = \"o-sylvester\"\n",
    "early_stopping = 200\n",
    "labels_per_class = 1000\n",
    "n_epochs = 100\n",
    "warmup = 0\n",
    "gt_input = 0\n",
    "\n",
    "# if ladder is yes builds a ladder vae. Do not combine with auxiliary (yet; might be possible and relatively \n",
    "# not too hard to implement, but might be overkill. Might be interesting too)\n",
    "translate = \"n\" \n",
    "\n",
    "# Convolution neural network (convolutional VAE and convolutional classifier)\n",
    "use_conv = False #Not applicable if not sequence (images, videos, sentences, DNA...)\n",
    "\n",
    "# Ladder VAE (L-VAE)\n",
    "ladder = False\n",
    "# Load pre-computed vae (unsupervised learning)\n",
    "load_vae = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lr = 1e-4\n",
    "l1 = 0.\n",
    "l2 = 0.\n",
    "batch_size = 128\n",
    "mc = 1 # seems to be a problem when mc > 1 for display only, results seem good\n",
    "iw = 1 # seems to be a problem when iw > 1 for display only, results seem good\n",
    "\n",
    "# Neurons layers\n",
    "h_dims = [128, 64]\n",
    "z_dims = [50]\n",
    "\n",
    "# number of flows\n",
    "number_of_flows = 8\n",
    "num_elements = 3\n",
    "\n",
    "is_example = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vae_flavour o-sylvester\n",
      "a_dim (making sure it stays ok for ssl_vae) 0\n",
      "self.a_dim 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simon/anaconda3/lib/python3.6/site-packages/torch/nn/_reduction.py:49: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No unlabelled data\n",
      "self.train_loader 468\n",
      "self.train_loader 128\n",
      "self.train_loader <torch.utils.data.sampler.RandomSampler object at 0x7f0230dca518>\n",
      "create model\n",
      "beta: 1.0\n",
      "Labelled 468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simon/anaconda3/lib/python3.6/site-packages/torch/tensor.py:287: UserWarning: non-inplace resize is deprecated\n",
      "  warnings.warn(\"non-inplace resize is deprecated\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVALUATION!\n",
      "Generating images\n",
      "GENERATING RANDOM IMAGES autoencoder!\n",
      "Images location: /home/simon//annleukemia/results/images/examples/generative/not_ladder/o-sylvester/\n",
      "GENERATING RECONSTRUCTION IMAGES autoencoder!\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[-1, 1, 28, 28]' is invalid for input of size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-fb950f61bcc2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/annleukemia/models/generative/autoencoders/autoencoder.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, epochs, clip_grad, gen_rate)\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0mtrain_loss_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_rec_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_kl_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_vae\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m             \u001b[0mval_loss_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_rec_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_kl_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_vae\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'validation'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loss_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0mtime_end\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/annleukemia/models/generative/autoencoders/autoencoder.py\u001b[0m in \u001b[0;36mevaluate_vae\u001b[0;34m(self, mode, calculate_likelihood, gen_rate)\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0;31m# if self.epoch % gen_rate == 0:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_random\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay_reconstruction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mrec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/annleukemia/models/generative/autoencoders/autoencoder.py\u001b[0m in \u001b[0;36mdisplay_reconstruction\u001b[0;34m(self, data, reconstruction)\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0mx_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_grid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         x_recon = reconstruction.view(-1, self.input_shape[0], self.input_shape[1],\n\u001b[0;32m--> 642\u001b[0;31m                                       self.input_shape[2]).data\n\u001b[0m\u001b[1;32m    643\u001b[0m         \u001b[0mx_recon_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_grid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_recon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[-1, 1, 28, 28]' is invalid for input of size 1"
     ]
    }
   ],
   "source": [
    "if ladder:\n",
    "    vae = LadderVariationalAutoencoder(vae_flavour, z_dims=z_dims, h_dims=h_dims, n_flows=number_of_flows,\n",
    "                                       num_elements=num_elements)\n",
    "    z_dim = z_dims[-1]\n",
    "elif vae_flavour in [\"o-sylvester\", \"h-sylvester\", \"t-sylvester\"]:\n",
    "    print(\"vae_flavour\", vae_flavour)\n",
    "    vae = SylvesterVAE(vae_flavour, z_dims=z_dims, h_dims=h_dims, n_flows=number_of_flows,\n",
    "                       num_elements=num_elements, auxiliary=False, a_dim=0)\n",
    "else:\n",
    "    print(\"vae_flavour\", vae_flavour)\n",
    "    vae = VariationalAutoencoder(vae_flavour, z_dim=z_dims, h_dims=h_dims, n_flows=number_of_flows, auxiliary=False, a_dim=0)\n",
    "    \n",
    "vae.load_example_dataset(dataset=\"mnist\", batch_size=batch_size, labels_per_class=0, extra_class=True, \n",
    "                         unlabelled_train_ds=None, normalize=True, mu=0.1307, var=0.3081, unlabelled_samples=False)\n",
    "\n",
    "train = np.vstack([x[0].data.numpy() for x in vae.x_train])\n",
    "#unlabelled_train = np.vstack([x[0].data.numpy() for x in dgm.unlabelled_x_train])\n",
    "\n",
    "targets = np.vstack([x[1].data.numpy() for x in vae.x_train])\n",
    "labels = [x.tolist().index(1) for x in targets]\n",
    "vae.set_configs(home_path=home_path, results_folder=results_folder, data_folder=data_folder,\n",
    "               destination_folder=destination_folder, dataset_name=dataset_name, lr=lr,\n",
    "               meta_destination_folder=\"meta_pandas_dataframes\", csv_filename=\"csv_loggers\")\n",
    "\n",
    "vae.define_configurations(vae_flavour, early_stopping=1000, warmup=warmup, ladder=ladder, z_dim=z_dims[-1], auxiliary=False, ssl=False)\n",
    "\n",
    "vae.set_data(is_example=is_example, labels_per_class=0)\n",
    "if ladder:\n",
    "    print(\"Setting ladder layers\")\n",
    "    vae.set_lvae_layers()\n",
    "else:\n",
    "    vae.set_vae_layers()\n",
    "\n",
    "if load_vae:\n",
    "    vae.load_model()\n",
    "\n",
    "vae.run(epochs=n_epochs, clip_grad=1e-4, gen_rate=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"PCA saved at: \", plots_folder_path)\n",
    "#meta_df = pd.DataFrame(train.transpose(), columns=labels)\n",
    "#ordination2d(meta_df, epoch=\"pre\", dataset_name=dataset_name, ord_type=\"pca\",\n",
    "#             images_folder_path=plots_folder_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References\n",
    "Auto-Encoding Variational Bayes https://arxiv.org/abs/1312.6114\n",
    "Semi-Supervised Learning with Deep Generative Models https://arxiv.org/abs/1406.5298\n",
    "Ladder Variational Autoencoders https://arxiv.org/abs/1602.02282\n",
    "Auxiliary Deep Generative Models    https://arxiv.org/abs/1602.05473\n",
    "Sylvester Normalizing Flows for Variational Inference  https://arxiv.org/abs/1803.05649\n",
    "Improving Variational Auto-Encoders using Householder Flow https://arxiv.org/abs/1611.09630\n",
    "Variational Inference with Normalizing Flows https://arxiv.org/abs/1505.05770\n",
    "Convex combination linear IAF and the Householder Flow, J.M. Tomczak & M. Welling https://jmtomczak.github.io/deebmed.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Github Ressources:\n",
    "    https://github.com/wohlert/semi-supervised-pytorch\n",
    "    https://github.com/jmtomczak/vae_vpflows\n",
    "    https://github.com/jmtomczak/vae_householder_flow"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "TO DO:\n",
    "    Calculate negative log-likelihood (to be maximized)\n",
    "    Get ordinations for all_samples AND generated samples in the SAME plot; \n",
    "        (make them the same color, but only the genwerated with a black contour, \n",
    "        or the opposite, or different contours)\n",
    "    Add Inverse Autoregressive Flow for variational inference (IAF; very common and apparently good; \n",
    "        the base for other flavours, such as sylvester flows (to be verified)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (GeoDataPreparation-master)",
   "language": "python",
   "name": "pycharm-8b38986"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
